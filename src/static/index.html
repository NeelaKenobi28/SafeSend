<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Interview Recorder with Video + TTS Questions</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 700px;
            margin: 30px auto;
            padding: 10px;
            line-height: 1.5;
        }

        #question {
            font-size: 1.25rem;
            margin-bottom: 1rem;
            min-height: 3rem;
        }

        #transcriptHistory {
            background: #f5f5f5;
            padding: 10px;
            border-radius: 4px;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 1rem;
            white-space: pre-wrap;
        }

        button {
            font-size: 1rem;
            padding: 10px 15px;
            margin-right: 10px;
        }

        p {
            margin: 0.25rem 0;
        }

        p strong {
            display: inline-block;
            width: 30px;
        }

        video {
            display: block;
            margin-bottom: 1rem;
            width: 100%;
            max-height: 300px;
            background: black;
        }
    </style>
</head>

<body>
<!-- Disclaimer Modal -->
<div id="disclaimerModal"
     style="display: flex; align-items: center; justify-content: center; position: fixed; z-index: 9999; left: 0; top: 0; width: 100vw; height: 100vh; background: rgba(0,0,0,0.5);">
    <div
            style="background: #fff; padding: 2rem; border-radius: 8px; max-width: 400px; text-align: center; box-shadow: 0 2px 16px rgba(0,0,0,0.2);">
        <h2>Welcome!</h2>
        <div>
            Hi! Welcome to your Video ID Verification! This is an automated process where you'll be asked some
            questions and you'll have to answer accordingly.
            <ul style="text-align: left;">
                <li>Make sure you are in a well-lit area.</li>
                <li>Ensure your camera and microphone are working properly.</li>
                <li>Once the question is asked, the recording will start and you'll have to present the answer.</li>
                <li> Once you're done recording, please hit on stop recording button.</li>
                <li><strong>Please answer accurately as your transaction approval depends on this.</strong></li>
            </ul>
        </div>
        <button id="closeDisclaimerBtn" style="margin-top: 1rem; padding: 8px 18px; font-size: 1rem;">Got
            it!</button>
    </div>
</div>
<h1>Video ID Verification</h1>
<div id="question">Loading question...</div>

<video id="videoPreview" autoplay muted></video>

<button id="startBtn" disabled>Start Recording</button>
<button id="stopBtn" disabled>Stop Recording</button>

<h3>Transcript History:</h3>
<div id="transcriptHistory"></div>

<script>
    const questions = [
        { id: 1, text: "Move your hand across the screen, such that it overlaps your face" },
        { id: 2, text: "What is your name?" },
        { id: 3, text: "Is this account related to you?" },
        { id: 4, text: "What is your address?" },
        { id: 5, text: "How much are you withdrawing in dollars?" },
    ];

    const expectedAnswers = {
        1: ["hand", "across", "overlap", "face"],
        2: ["Bob", "James", "Tom", "Mike", "Ronald", "Chris"],
        3: ["yes", "account", "related"],
        4: ["address", "live at", "my address is"],
        5: ["amount", "withdrawing", "dollars", "rupees"],

    };

    // 2. Add a function to check if the answer matches expected keywords
    // function answerIsCorrect(questionId, transcriptText) {
    //     console.log("here", questionId, transcriptText);
    //     const expected = expectedAnswers[questionId];
    //     if (!expected) return false;
    //     const lowerTranscript = transcriptText.toLowerCase();
    //     return expected.some(keyword => lowerTranscript.includes(keyword));
    // }

    let currentQuestion = questions[0];
    let mediaRecorder;
    let recordedChunks = [];
    let localStream;

    const questionEl = document.getElementById('question');
    const transcriptHistoryEl = document.getElementById('transcriptHistory');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const videoPreview = document.getElementById('videoPreview');

    function speakQuestion(text) {
        return new Promise((resolve) => {
            if (!window.speechSynthesis) {
                alert('Sorry, your browser does not support speech synthesis.');
                resolve();
                return;
            }

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.onend = () => resolve();
            utterance.onerror = () => resolve();

            window.speechSynthesis.speak(utterance);
        });
    }

    async function displayQuestion(question) {
        if (!question) {
            questionEl.textContent = "Verification completed. Thank you!";
            startBtn.disabled = true;
            stopBtn.disabled = true;
            if (localStream) {
                localStream.getTracks().forEach(t => t.stop());
                videoPreview.srcObject = null;
            }
            return;
        }

        questionEl.textContent = '';
        startBtn.disabled = true;
        stopBtn.disabled = true;

        await speakQuestion(question.text);

        questionEl.textContent = question.text;
        startRecording();
    }

    function getNextQuestion(transcriptText) {
        if (transcriptText.toLowerCase().includes('developer')) {
            return { id: 99, text: "Can you tell me about your coding skills?" };
        }
        const currentIndex = questions.findIndex(q => q.id === currentQuestion.id);
        if (currentIndex + 1 < questions.length) {
            return questions[currentIndex + 1];
        }
        return null;
    }

    async function transcribeAudio(blob) {
        const formData = new FormData();
        formData.append('file', blob, 'recording.webm');
        formData.append('question', currentQuestion.text); // âœ… Add this line

        try {
            const response = await fetch('/transcribe', {
                method: 'POST',
                body: formData
            });
            const data = await response.json();

            if (data.error) {
                return 'Transcription error: ' + data.error;
            }
            return data;
        } catch (err) {
            return 'Network error: ' + err.message;
        }
    }


    async function startMedia() {
        try {
            localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
            videoPreview.srcObject = localStream;
        } catch (err) {
            alert('Could not access camera and microphone: ' + err.message);
        }
    }

    function startRecording() {
        if (!localStream) {
            alert('No media stream available.');
            return;
        }

        recordedChunks = [];
        mediaRecorder = new MediaRecorder(localStream, { mimeType: 'video/webm; codecs=vp8,opus' });

        mediaRecorder.ondataavailable = e => {
            if (e.data.size > 0) recordedChunks.push(e.data);
        };

        // ...inside mediaRecorder.onstop...
        mediaRecorder.onstop = async () => {
            const videoBlob = new Blob(recordedChunks, { type: 'video/webm' });

            transcriptHistoryEl.innerHTML +=
                `<p><strong>Q:</strong> ${currentQuestion.text}</p>` +
                `<p><strong>A:</strong> <em>Transcribing...</em></p>`;
            transcriptHistoryEl.scrollTop = transcriptHistoryEl.scrollHeight;

            const paragraphs = transcriptHistoryEl.querySelectorAll('p');
            const lastAnswerP = paragraphs[paragraphs.length - 1];

            // Expect backend to return { text: "...", valid: true/false, speak?: "..." }
            const result = await transcribeAudio(videoBlob);
            console.log('transcribeAudio result:',result)
            let transcriptText = '';
            let speakMessage = '';
            let valid = null;

            transcriptText = result.text || '[No transcription available]';
            console.log('transcriptText', transcriptText)
            speakMessage = result.speak || '';
            console.log('speakMessage', speakMessage)
            valid = result.valid;
            console.log('valid', valid)


            // Show tick or cross based on backend validation
            let icon = '';
            if (valid === true) {
                icon = ' <span style="color:green;font-size:1.2em;">&#10004;</span>';
                console.log('true case icon:',icon)
            } else if (valid === false) {
                icon = ' <span style="color:red;font-size:1.2em;">&#10060;</span>';
                console.log('false case icon:',icon)
            }

            lastAnswerP.innerHTML = `<strong>A:</strong> ${transcriptText}${icon}`;

            if (speakMessage) {
                await speakQuestion(speakMessage);
            }
            // **Stop flow if user not recognized message received**
            if (speakMessage.toLowerCase().includes('not recognized')) {
                console.log("User not recognized. Ending interview.");
                questionEl.textContent = "User not recognized. Interview ended.";
                startBtn.disabled = true;
                stopBtn.disabled = true;
                if (localStream) {
                    localStream.getTracks().forEach(t => t.stop());
                    videoPreview.srcObject = null;
                }
                return; // Stop further questions
            }

            // Continue normal flow if user recognized
            const nextQuestion = getNextQuestion(transcriptText);
            currentQuestion = nextQuestion;

            setTimeout(() => displayQuestion(currentQuestion), 1500);
        };
        mediaRecorder.start();
        startBtn.disabled = true;
        stopBtn.disabled = false;
    };

    stopBtn.addEventListener('click', () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    });

    // Start camera + mic on page load and begin interview
    // (async () => {
    //     await startMedia();
    //     await displayQuestion(currentQuestion);
    // })();
    // Show disclaimer modal on page load
    window.addEventListener('DOMContentLoaded', () => {
        const modal = document.getElementById('disclaimerModal');
        const closeBtn = document.getElementById('closeDisclaimerBtn');
        modal.style.display = 'flex';
        closeBtn.onclick = async () => {
            modal.style.display = 'none';
            await startMedia();
            await displayQuestion(currentQuestion);
        };
    });
</script>
</body>

</html>